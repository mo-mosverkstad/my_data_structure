Hashtable: Most natural way to organize a set of entries that should be accessible given a key. 

Table of Swedish zip codes:
The original file is in a CSV format (comma separated value), there are 9675 entries in total ??? Where file ???.

We will read the file and insert each item in a array of entries. Each entry consists of the zip code, the name of the area and the population. Reading the file and adding them all to an array.

1. Now write a lookup method that does a linear search through all zip codes looking for a specific entry. Then, since the zip codes in the file are ordered, you can write a binary search method that does the same. Write a small benchmark that searches for â€111 15â€ and â€984 99â€ and explain the results.


2. Since we know that all zip codes are numbers we might as well convert them to Integers before creating the entries. Create a new version of your zip program. Re-run all benchmarks and presents the results, has the execution time improved?

3. If we have the zip code as the key and the key is an integer, why not use that integer as an index in an array? We know that the highest possible key is 99999 so why not construct an array that is a hundred thousand elements large and then use the key as index.

Size problem:
The only drawback with the implementation that you have now is that the array is to 90% empty. You have an array of a hundred thousand elements but there are less then ten thousand zip codes. 
The solution is to somehow transform the original key into an index in a smaller array. If we can find a function that takes a zip code key and returns an index in the range 0 to letâ€™s say 10000 then the problem would be solved. 
The function could not be too time consuming since the whole point is to save time so it should be very simple. The function that transforms a key to an index is called a hash function.
One simple way of defining a hash function is to simply take the key modulo some value m in hope that the indexes should be fairly unique. If we have two keys that maps to the same index then we have collision that is something that we need to handle (and will be able to handle) but the fewer collisions better

4. Do an experiment where you read all the zip codes from the file and then run through them creating an index modulo m for some values of m (10000, 20000 ...). Your experiment should count the number of collisions of each type i.e. two keys map to the same index, three keys map to the same index etc. The following skeleton code should get you starting:

Finding a hash function is always a trade off between the size of the array (the maximum index) and the number of collisions. The larger array that is used the less collisions will you likely have but the more space is wasted.
A larger array does not necessarily mean that we will have less collisions. Try the following three values: 13513, 13600 and 14000 - did the larger size help?





Based on the assignment PDF you provided, there are **six major tasks** you are expected to complete.  
Here is the clear breakdown:

***

# âœ… **1. Implement linear search**

*   Write a function that scans through all entries sequentially and finds a ZIP code.

***

# âœ… **2. Implement binary search**

*   Since the input file is sorted, write a binary search function.
*   Benchmark both linear and binary search using ZIP:
    *   `111 15`
    *   `984 99`

***

# âœ… **3. Convert ZIP codes to integers and redo benchmarks**

You must:

*   Change the `area` structure to store `int zip` instead of string.
*   Convert formats like `"111 15"` to integer:  
    `a.zip = atoi(zip)*100 + atoi(zip+3);`
*   Rerun the benchmarks from Tasks 1 & 2.
*   Compare performance.

***

# âœ… **4. Use the ZIP code *as an array index* (direct indexing)**

*   Create an array of size **100000**.
*   Use the integer ZIP code as the direct index.
*   Implement fast lookup.
*   Benchmark and compare with binary search.

***

# âœ… **5. Hash function + collision analysis**

*   Use `zip % m` as the hash function.
*   For various values of `m` (e.g., 10000, 20000, 12345, 17389, 13513, 13600, 14000):
    *   Count how many collisions occur.
    *   Produce a distribution:  
        â€œhow many buckets have 1 element, 2 elements, 3 elements, â€¦â€
*   Analyze differences when `m` changes.

***

# âœ… **6. Implement two hash tables with collision handling**

This is the biggest part and contains two subâ€‘tasks:

## 6a) **Separate chaining**

*   Implement an array of buckets (linked lists).
*   Insert all ZIP entries.
*   Implement lookup.

## 6b) **Linear probing (open addressing)**

*   Reuse the array itself.
*   On collision, move forward until an empty slot is found.
*   Implement lookup that stops when an empty slot is found.
*   Run statistics on:
    *   Average number of steps required
    *   Comparison for various table sizes

***

# ğŸ¯ **Total tasks: 6 main tasks (with 2 subâ€‘tasks in task 6)**

If you prefer a strict count:

*   **6 major tasks**
*   **7 or 8 subâ€‘tasks** depending on granularity (benchmarks, integer conversion, collision analysis, two hashâ€‘table collision methods).

***






Short answer: **Yesâ€”the trends in your results match the analysis.**  
But the **magnitudes** (especially for linear probing) show **much more clustering than the uniformâ€‘hashing theory predicts**, which strongly suggests your current hash `index = zip % m` is interacting with the structure of Swedish postcodes and the chosen `m` values.

Below Iâ€™ll walk through what matches, what doesnâ€™t, and what to do next.

***

## âœ… What matches the theory

### 1) Separate chaining (bucketed hash table)

*   As you **increase table size `m`** (e.g., from 10â€¯000 to 20â€¯000), you see **far more empty buckets** and **fewer high-occupancy buckets**. Thatâ€™s exactly what we expect: lower load factor $$\alpha = n/m$$ spreads keys out and reduces collisions.  
    *(Your distributions clearly shift mass from buckets with 1â€“5 items toward 0â€“1 as `m` growsâ€”this is the textbook trend.)*

*   Changing `m` **changes the collision profile**. Your runs with **primes** (e.g., 13â€¯513, 17â€¯389) generally look better behaved than **round numbers** (e.g., 13â€¯600, 14â€¯000), which is consistent with the idea that `zip % m` can align badly when `m` has small factors and keys have structure.

### 2) Linear probing (open addressing)

*   **Monotone trend w\.r.t. load factor:** As `m` grows (and $$\alpha = n/m$$ drops), your **average probes** fall dramaticallyâ€”catastrophic near $$\alpha \approx 1$$, still large at $$\alpha \approx 0.8$$, much smaller by $$\alpha \approx 0.5$$. This is exactly the qualitative story: nearâ€‘full tables explode in probe length; roomy tables are much faster.

*   **Worstâ€‘case grows toward $$O(n)$$ when the table is tight**: At `m = 9677` (â‰ˆ full), your max probes are **9â€¯623**, i.e., close to scanning the whole table. Thatâ€™s exactly the â€œnear full â‡’ worstâ€‘case $$O(n)$$â€ behavior we discussed.

***

## âš ï¸ Where your numbers diverge (and why)

Under the standard **uniform hashing** assumption, the wellâ€‘known approximation for **successful search with linear probing** is:

$$
\mathbb{E}[\text{slots examined}] \;\approx\; \tfrac{1}{2}\Big(1 + \tfrac{1}{1-\alpha}\Big)
\quad\Rightarrow\quad
\mathbb{E}[\text{probes}] \;\approx\; \tfrac{1}{2}\Big(1 + \tfrac{1}{1-\alpha}\Big) - 1.
$$

*   For **moderate load** (say $$\alpha \approx 0.5\text{â€“}0.8$$), this predicts **about 1.5â€“3 slots** on average.
*   In your data, even at $$\alpha \approx 0.5$$ (e.g., `m=19373`), you measure **â‰ˆâ€¯4.06 slots**; at $$\alpha \approx 0.8$$ (e.g., `m=12097`), you measure **â‰ˆâ€¯26.8 slots**â€”an order of magnitude above the uniform model.

**Interpretation:** your hash `zip % m` is **not uniform** for these keys and moduli. Swedish postcodes are highly structured; when `m` is composite (e.g., **14â€¯000, 13â€¯600, 20â€¯000**), the last digits and ranges of `zip` tend to **pile into runs of indices**, creating **primary clustering** that linear probing amplifies. This also shows up in separate chaining as **more empties** (and fewer nonâ€‘empty buckets) than a Poissonâ€‘like spread would predictâ€”i.e., keys concentrate into fewer buckets rather than sprinkling uniformly.

You can also see that **primes help**:

*   At **`m=19â€¯373 (â‰ˆ 2Ã—n, prime)`**, your mean is â‰ˆ **4.06 slots**â€”still above theory but **much closer** than composite sizes near the same load factor.
*   At composite sizes (**14â€¯000, 13â€¯600, 20â€¯000**) your means jump way up despite similar or even **lower** load factors, again pointing at **hashâ€“modulus interaction** rather than pure load factor.

***

## ğŸ“Œ Bottom line

*   **Trends match**: Bigger table â‡’ fewer probes; nearâ€‘full â‡’ catastrophic; chaining improves as `m` grows; primes typically beat â€œroundâ€ sizes.
*   **Magnitudes donâ€™t match uniform theory**: Your averages are **much higher** than $$\tfrac{1}{2}(1 + 1/(1-\alpha))$$ would suggest. Thatâ€™s **not a contradiction**â€”it just means **uniform hashing does not hold** with `index = zip % m` for these datasets.

***

## âœ… What to do to match theory more closely (and speed things up)

If you want your measured means to approach the textbook values:

1.  **Mix the integer key before indexing** (donâ€™t use raw `zip % m`):
    ```c
    // 32-bit mix, inexpensive and good enough for lab work
    uint32_t x = (uint32_t)zip;
    x ^= x >> 16;
    x *= 0x7feb352d;
    x ^= x >> 15;
    x *= 0x846ca68b;
    x ^= x >> 16;
    int idx = (int)(x % m);        // or mask if capacity is a power of two
    ```
    This destroys regular patterns in the postal codes so buckets/probe starts are more uniform.

2.  **Prefer prime capacities** for `% m` hashing (e.g., 13â€¯513, 14â€¯519, 17â€¯389, 19â€¯373).  
    If you need **powerâ€‘ofâ€‘two** tables for speed, then **mask** (`idx = x & (m-1)`) but **only after mixing** (as above), otherwise low bits of `zip` will dominate.

3.  For open addressing, consider **double hashing** (second step like `1 + (x % (m-1))`) instead of pure linear probing to reduce clustering in the probe sequence.

If you like, share a reâ€‘run for, say, **`m=19373` with the mix above**â€”I expect your **mean slots** to come down significantly toward the theoretical \~**1.5â€“2.0** range at $$\alpha \approx 0.5$$, and your high percentiles to tighten as well.

***

## ğŸ§­ How to write this up in your report

*   **State the theory qualitatively** (as you quoted): O(1) average at low load; grows toward O(n) as load $$\to 1$$; worstâ€‘case O(n).
*   **Show your measurements** and **call out the divergence** in magnitude: â€œOur measured averages exceed the uniformâ€‘hash prediction by factors ranging from \~2Ã— to >10Ã— for certain `m`.â€
*   **Explain why** (nonâ€‘uniform hashing + clustering) and **demonstrate the fix** (key mixing and/or prime `m`) with a before/after table.

If you want, I can **generate a small â€œbefore/afterâ€ experiment** plus a LaTeX table or plot you can paste directly into the report.
